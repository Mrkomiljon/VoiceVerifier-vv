import os
import torchaudio
import joblib
import torch
import numpy as np
from speechbrain.inference import EncoderClassifier
from sklearn.metrics.pairwise import cosine_similarity
from remove_silence import remove_silence, save_audio  

# ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë° ì„ë² ë”© ë¶„ë¥˜ê¸° ë¡œë“œ
classifier = EncoderClassifier.from_hparams(source="speechbrain/spkrec-ecapa-voxceleb")
model = joblib.load("C:\\Users\\GOOD\\Desktop\\Komil\\Call_center\\embedding_labels\\final_voice_classifier.pkl")

# í•™ìŠµëœ ì„ë² ë”©ì„ ë¶ˆëŸ¬ì™€ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í‰ê·  ì„ë² ë”© ê³„ì‚°
X_train = np.load("C:\\Users\\GOOD\\Desktop\\Komil\\Call_center\\embedding_labels\\X_train.npy")
y_train = np.load("C:\\Users\\GOOD\\Desktop\\Komil\\Call_center\\embedding_labels\\y_train.npy")
class_means = [X_train[y_train == cls].mean(axis=0) for cls in range(3)]

def get_embedding(audio_path, segment_duration=10, sample_rate=16000):
    signal, fs = torchaudio.load(audio_path)
    if fs != sample_rate:
        signal = torchaudio.transforms.Resample(fs, sample_rate)(signal)

    total_samples = signal.shape[1]
    segment_samples = segment_duration * sample_rate

    embeddings = []
    for start in range(0, total_samples, segment_samples):
        end = min(start + segment_samples, total_samples)
        segment = signal[:, start:end]

        if segment.shape[1] < int(0.5 * segment_samples):
            continue

        emb = classifier.encode_batch(segment).squeeze().detach().cpu().numpy()
        embeddings.append(emb)

    if embeddings:
        return np.mean(embeddings, axis=0)
    else:
        return np.array([])

# ----- ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ë¥¼ ìœ„í•œ ì¶”ë¡  ----- #

audio_path = "C:\\Users\\GOOD\\Desktop\\Komil\\deepvoicechanger_ys\\audio\\11.wav"

# ì •ë¦¬ëœ ì˜¤ë””ì˜¤ íŒŒì¼ëª… ìƒì„± (ì›ë³¸ íŒŒì¼ëª… ìœ ì§€)
file_name = os.path.basename(audio_path)  # ì˜ˆ: '103_Modern.wav'
clean_audio_path = os.path.join("C:\\Users\\GOOD\\Desktop\\Komil\\deepvoicechanger_ys\\audio", f"clean_{file_name}")

# 1ë‹¨ê³„: ë¬´ìŒ ë¶€ë¶„ ì œê±°
clean_audio, fs = remove_silence(audio_path)

# ğŸ”¹ DEBUG: fs í™•ì¸
print(f"ğŸŸ¡ ë””ë²„ê·¸: clean_audio íƒ€ì…: {type(clean_audio)}, í˜•íƒœ: {clean_audio.shape if isinstance(clean_audio, torch.Tensor) else 'N/A'}")
print(f"ğŸŸ¡ ë””ë²„ê·¸: fs íƒ€ì…: {type(fs)}, ê°’: {fs}")

# fsê°€ ì˜ëª»ëœ í˜•ì‹ì´ë©´ 16000ìœ¼ë¡œ ì„¤ì •
if not isinstance(fs, int):
    fs = 16000  # ê¸°ë³¸ ìƒ˜í”Œë§ ì†ë„
if not isinstance(clean_audio, torch.Tensor) or clean_audio.numel() == 0:
    print(f"âŒ {file_name} - ì˜¤ë””ì˜¤ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¹ˆ ì„ë² ë”©ì…ë‹ˆë‹¤. íŒŒì¼ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
else:
    # ğŸ”¹ `clean_audio`ë¥¼ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    if clean_audio.dtype != torch.float32:
        clean_audio = clean_audio.to(torch.float32)
    
    # ğŸ”¹ 2D ë³€í™˜ (torchaudio.saveë¥¼ ìœ„í•œ ì¡°ì¹˜)
    if clean_audio.dim() == 1:
        clean_audio = clean_audio.unsqueeze(0)

    # ğŸ”¹ NumPy ë°°ì—´ë¡œ ë³€í™˜
    clean_audio_np = clean_audio.squeeze().cpu().numpy()

    # ğŸ”¹ ì •ë¦¬ëœ ì˜¤ë””ì˜¤ ì €ì¥
    print(f"ğŸŸ¡ ë””ë²„ê·¸: save_audio í˜¸ì¶œ -> íƒ€ì…: {type(clean_audio_np)}, í˜•íƒœ: {clean_audio_np.shape}, dtype: {clean_audio_np.dtype}")
    
    torchaudio.save(clean_audio_path, torch.tensor(clean_audio_np).unsqueeze(0), fs)
    print(f"âœ… ì˜¤ë””ì˜¤ê°€ ì •ë¦¬ë˜ì—ˆìœ¼ë©° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {clean_audio_path}")

    # 2ë‹¨ê³„: ì˜¤ë””ì˜¤ ì„ë² ë”© ì¶”ì¶œ
    embedding = get_embedding(clean_audio_path)

    if embedding.size > 0:
        # 3ë‹¨ê³„: ëª¨ë¸ì„ í†µí•œ ìœ ì‚¬ì„± ê²€ì‚¬ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
        similarities = cosine_similarity([embedding], class_means)[0]
        max_similarity = max(similarities)
        predicted_class = np.argmax(similarities)

        print(f"ğŸ”¹ ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {similarities}")

        # 4ë‹¨ê³„: ì„ê³„ê°’ì„ í†µí•´ ìµœì¢… ê²°ì •
        if max_similarity < 0.6:
            print(f"âŒ {file_name} - ì´ ì˜¤ë””ì˜¤ëŠ” ê¸°ì¡´ í´ë˜ìŠ¤ì™€ ìœ ì‚¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ì•Œ ìˆ˜ ì—†ëŠ” ìŒì„±).")
        else:
            print(f"âœ… {file_name} - ì´ ì˜¤ë””ì˜¤ëŠ” {predicted_class+1}ë²ˆ ì£¼ìš” ìŒì„± ìœ í˜•ì— ì†í•©ë‹ˆë‹¤ (ìœ ì‚¬ë„: {max_similarity:.2f}).")
    else:
        print(f"âŒ {file_name} - ì„ë² ë”©ì„ ì–»ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì§§ìŒ).")
