import os
import torch
import torchaudio
import numpy as np
import joblib
from fastapi import FastAPI, UploadFile, File
from speechbrain.inference import EncoderClassifier
from sklearn.metrics.pairwise import cosine_similarity
from remove_silence import remove_silence

app = FastAPI()

# ğŸ”¹ Model va embeddinglar yuklash
print("ğŸ“¦ ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
classifier = EncoderClassifier.from_hparams(source="speechbrain/spkrec-ecapa-voxceleb")
model = joblib.load("embedding_labels/final_voice_classifier.pkl")
X_train = np.load("embedding_labels/X_train.npy")
y_train = np.load("embedding_labels/y_train.npy")
class_means = [X_train[y_train == cls].mean(axis=0) for cls in range(3)]
print("âœ… ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ğŸ”¹ Foydali funksiya: audioni saqlash
def save_audio(tensor, path, sample_rate):
    if tensor.dtype != torch.float32:
        tensor = tensor.to(torch.float32)
    if tensor.dim() == 1:
        tensor = tensor.unsqueeze(0)
    torchaudio.save(path, tensor, sample_rate)

# ğŸ”¹ Embedding olish
def get_embedding(audio_path, segment_duration=10, sample_rate=16000):
    signal, fs = torchaudio.load(audio_path)
    if fs != sample_rate:
        signal = torchaudio.transforms.Resample(fs, sample_rate)(signal)

    total_samples = signal.shape[1]
    segment_samples = segment_duration * sample_rate

    embeddings = []
    for start in range(0, total_samples, segment_samples):
        end = min(start + segment_samples, total_samples)
        segment = signal[:, start:end]
        if segment.shape[1] < int(0.5 * segment_samples):
            continue
        emb = classifier.encode_batch(segment).squeeze().detach().cpu().numpy()
        embeddings.append(emb)

    if embeddings:
        return np.mean(embeddings, axis=0)
    else:
        return np.array([])

# ğŸ”¹ Asosiy prediksiya funksiyasi
def predict(audio_file, upload_dir="audio"):
    os.makedirs(upload_dir, exist_ok=True)

    filename = os.path.basename(audio_file.filename)
    raw_path = os.path.join(upload_dir, filename)

    with open(raw_path, "wb") as f:
        f.write(audio_file.file.read())

    # 1. remove silence
    clean_audio, fs = remove_silence(raw_path)
    if not isinstance(clean_audio, torch.Tensor) or clean_audio.numel() == 0:
        return {"status": "error", "message": "ë¹ˆ ì˜¤ë””ì˜¤ì´ê±°ë‚˜ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    clean_path = os.path.join(upload_dir, f"clean_{filename}")
    save_audio(clean_audio, clean_path, fs if isinstance(fs, int) else 16000)

    # 2. extract embedding
    embedding = get_embedding(clean_path)
    if embedding.size == 0:
        return {"status": "error", "message": "ì„ë² ë”© ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}

    # 3. cosine similarity
    similarities = cosine_similarity([embedding], class_means)[0]
    max_sim = max(similarities)
    pred_class = int(np.argmax(similarities)) + 1

    if max_sim < 0.6:
        return {
            "status": "unknown",
            "similarity": float(max_sim),
            "message": "ì´ ìŒì„±ì€ ì•Œë ¤ì§„ ìŒì„± ìœ í˜•ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        }
    else:
        return {
            "status": "success",
            "predicted_class": pred_class,
            "similarity": float(max_sim),
            "message": f"ì´ ìŒì„±ì€ {pred_class}ë²ˆ ìŒì„± ìœ í˜•ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤."
        }

# ğŸ”¹ FastAPI endpointlari
@app.get("/")
def home():
    return {"message": "ìŒì„± ë¶„ë¥˜ APIê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤!"}

@app.post("/predict")
async def classify_voice(file: UploadFile = File(...)):
    result = predict(file)
    return result
