# ğŸ™ï¸ VoiceVerifier-vv
A FastAPI-powered voice classification system that identifies speaker types from uploaded audio files. It leverages **SpeechBrainâ€™s ECAPA-TDNN** model to extract speaker embeddings, removes silence using **Silero VAD**, and classifies voices using a **Random Forest** model based on **cosine similarity**.

---

## ğŸ“Œ Project Summary

This project helps identify a speakerâ€™s voice type (e.g., modern, lofi, emo) based on their audio characteristics. It includes a full pipeline for:

- Preparing and cleaning audio data
- Extracting embeddings
- Training a classifier
- Running real-time inference via API

---

## ğŸ› ï¸ Tech Stack

- **Python 3.8+**
- [FastAPI](https://fastapi.tiangolo.com/) â€” for REST API
- [SpeechBrain](https://speechbrain.readthedocs.io/) â€” ECAPA-TDNN speaker encoder
- [Silero VAD](https://github.com/snakers4/silero-vad) â€” for silence removal
- **Scikit-learn** â€” for RandomForestClassifier and evaluation
- **TorchAudio** â€” for audio loading/saving

---

## ğŸ—ï¸ Full Pipeline Overview

### 1. ğŸ§ **Audio Data Regrouping**
Script: `1_data-regrouping.py`

- Original dataset contains raw audio clips with various keywords.
- Files are reorganized into:
dataset/
* â”œâ”€â”€ speaker_1/ # 'modern'
- â”œâ”€â”€ speaker_2/ # 'lofi'
- â”œâ”€â”€ speaker_3/ # 'emo'
- â”œâ”€â”€
- â”œâ”€â”€
- â”œâ”€â”€ speaker_n/ # 'name'
  
### 2. ğŸ”‡ **Silence Removal**
Script: `2_prepare_clean_dataset.py`

- Uses **Silero VAD** to detect speech segments.
- Non-speech parts are removed.
- Output is saved in `clean_dataset/`.

### 3. ğŸ§  **Embedding Extraction**
Script: `3_prepare_embeddings.py`

- SpeechBrainâ€™s ECAPA-TDNN model extracts a vector representation (embedding) of each voice.
- Embeddings and labels are saved as `.npy` files.

### 4. âœ‚ï¸ **Train/Test Split**
Script: `4_train_test_split.py`

- Embeddings are split into training and test sets using stratified sampling.

### 5. ğŸ§ª **Model Training**
Script: `5_train_model.py`

- A **Random Forest Classifier** is trained on the speaker embeddings.
- The trained model is saved as: `final_voice_classifier.pkl`.

### 6. ğŸ“Š **Evaluation**
Script: `evaluate_model.py`

- Model is evaluated on the test set.
- Reports:
- Classification Report (precision, recall, f1-score)
- Confusion Matrix

### 7. ğŸ” **Inference & Prediction**
Scripts: `7_inference.py` and `voice_classifier_api.py`

- Runs inference on new audio files.
- Predicts class by comparing the embedding to class centroids using **cosine similarity**.
- If similarity < 0.6 â†’ labeled as "unknown".

---

## âš™ï¸ Installation

```bash
# Clone the repo
git clone https://github.com/Mrkomiljon/VoiceVerifier-vv.git
cd VoiceVerifier-vv
```

```
# Install dependencies
pip install -r requirements.txt
```
- Ensure you have ffmpeg installed to support all audio formats (.mp3, .flac, etc.).
## â–¶ï¸ Run FastAPI Server
```
uvicorn voice_classifier_api:app --reload
```
API will be available at:
http://127.0.0.1:8000

ğŸ“¡ API Endpoints
GET /
Test endpoint to check if the API is running.

POST /predict
Upload an audio file to get the predicted speaker class.

Example (using curl):
```
curl -X POST "http://127.0.0.1:8000/predict" \
  -H  "accept: application/json" \
  -H  "Content-Type: multipart/form-data" \
  -F "file=@test_audio.wav"
```
## ğŸ§ª Example Output
![image](https://github.com/user-attachments/assets/de5ee3da-4077-405e-8151-2f2853484651)

```
{
  "status": "success",
  "predicted_class": 1,
  "similarity": 0.9178803563117981,
  "message": "ì´ ìŒì„±ì€ 1ë²ˆ ìŒì„± ìœ í˜•ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤."
}
```
If similarity is below threshold:

![image](https://github.com/user-attachments/assets/93cee9ed-5e46-4e8f-8c00-9cb1d3ce6a62)

```
{
  "status": "unknown",
  "similarity": 0.08953896909952164,
  "message": "ì´ ìŒì„±ì€ ì•Œë ¤ì§„ ìŒì„± ìœ í˜•ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
}
```
ğŸ§° Utilities
remove_silence.py
Uses Silero VAD to remove non-speech regions from audio.
## ğŸ“‚ Directory Structure
```
â”œâ”€â”€ audio/                          # Temporary folder for uploads
â”œâ”€â”€ dataset/                        # Original grouped audio
â”œâ”€â”€ clean_dataset/                 # Audio after silence removal
â”œâ”€â”€ embedding_labels/              # Saved embeddings & labels
â”œâ”€â”€ final_voice_classifier.pkl     # Trained model
â”œâ”€â”€ *.py                           # All functional scripts
```
ğŸ“ˆ Model Details
Embedding Model: speechbrain/spkrec-ecapa-voxceleb

Classifier: RandomForest (200 estimators)

Threshold: Cosine similarity threshold of 0.6

ğŸ”’ License
MIT License â€” use freely with attribution.

ğŸ™Œ Acknowledgements
* [SpeechBrain](https://speechbrain.readthedocs.io/en/latest/)
* [Silero VAD](https://github.com/snakers4/silero-vad)
* [FastAPI](https://fastapi.tiangolo.com/)



